{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# same step to LVQ/KNN\n",
    "#scikit-learn, matplotlib\n",
    "#pip install sklvq\n",
    "\n",
    "import pandas as pd\n",
    "df = pd.read_csv('bank-additional-full.csv', sep= ';')\n",
    "\n",
    "# input missing values?\n",
    "#df['Item_Weight'].fillna(mean, inplace =True)\n",
    "\n",
    "df = df[['age', 'job','marital','education','default','housing', 'loan', 'y']].dropna()\n",
    "df.replace({'yes': 0, 'no': 1}, inplace=True)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "train, test = train_test_split(df, test_size = 0.6, shuffle=True)\n",
    "\n",
    "x_train = pd.get_dummies(train, prefix=['job','marital','education','default','housing', 'loan'])\n",
    "y_train = x_train[\"y\"]\n",
    "x_train.drop(\"y\", axis=1, inplace=True)\n",
    "\n",
    "x_test = pd.get_dummies(test, prefix=['job','marital','education','default','housing', 'loan'])\n",
    "y_test = x_test[\"y\"]\n",
    "x_test.drop(\"y\", axis=1, inplace=True)\n",
    "\n",
    "# normalização\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "\n",
    "x_train_scaled = scaler.fit_transform(x_train)\n",
    "x_train = pd.DataFrame(x_train_scaled)\n",
    "\n",
    "x_test_scaled = scaler.fit_transform(x_test)\n",
    "x_test = pd.DataFrame(x_test_scaled)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklvq import GLVQ\n",
    "\n",
    "# Sklearn's standardscaler to perform z-transform\n",
    "#scaler = StandardScaler()\n",
    "\n",
    "# Compute (fit) and apply (transform) z-transform\n",
    "#df1 = scaler.fit_transform(df)\n",
    "\n",
    "# The creation of the model object used to fit the data to.\n",
    "model = GLVQ(\n",
    "    distance_type=\"squared-euclidean\",\n",
    "    activation_type=\"swish\",\n",
    "    activation_params={\"beta\": 2},\n",
    "    solver_type=\"steepest-gradient-descent\",\n",
    "    solver_params={\"max_runs\": 20, \"step_size\": 0.1},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00      2760\n",
      "           1       0.89      1.00      0.94     21953\n",
      "\n",
      "    accuracy                           0.89     24713\n",
      "   macro avg       0.44      0.50      0.47     24713\n",
      "weighted avg       0.79      0.89      0.84     24713\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ejcas/miniconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/ejcas/miniconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/ejcas/miniconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Train the model using the iris dataset\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "# Predict the labels using the trained model\n",
    "predicted_labels = model.predict(x_test)\n",
    "\n",
    "# To get a sense of the training performance we could print the classification report.\n",
    "print(classification_report(y_test, predicted_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implementação antiga:\n",
    "#LVQ - código em https://towardsdatascience.com/learning-vector-quantization-ed825f8c807d\n",
    "import numpy as np\n",
    "\n",
    "#train_lvq: trains an lvq system using the given training data corresponding labels\n",
    "#Run the desired number of epochs using the given learning rate. Optional validation set to monitor performance.\n",
    "\n",
    "def train_lvq(data, labels, num_epochs, learning_rate, validation_data=None, validation_labels=None):\n",
    "  #Get unique class labels\n",
    "  num_dims = data.shape[1] #número de dimensões\n",
    "  labels=labels.astype(int)\n",
    "  unique_labels =list(set(labels))\n",
    "\n",
    "  num_protos = len(unique_labels) #tamanho do grupo\n",
    "  prototypes = np.empty((num_protos, num_dims)) #matriz com o tamanho da labels unicas e número de dimensões\n",
    "  proto_labels = []\n",
    "\n",
    "  #input_data = data.drop(\"y\", axis=1, inplace=False)\n",
    "  #input_validation_data = validation_data.drop(\"y\", axis=1, inplace=False)\n",
    "\n",
    "  #initialize prototypes using class means - o protótipo é inicializado com a media da classe\n",
    "  for i in unique_labels:\n",
    "    #class_data = data[labels ==i,:]\n",
    "    class_data=list(map(lambda s: s[0], filter(lambda s: s[1] == i, zip(data.values,labels))))\n",
    "\n",
    "    #compute class mean\n",
    "    #mean = np.mean(class_data, axis=0)\n",
    "    mean = np.mean(class_data, axis=0)\n",
    "    print(i, mean)\n",
    "\n",
    "    prototypes[i] = mean\n",
    "    proto_labels.append(i)\n",
    "\n",
    "\n",
    "  #Loop through data set\n",
    "  for epoch in range (0, num_epochs):\n",
    "    for fvec, lbl in zip (data,labels):\n",
    "      #compute distance from each prototype to this point\n",
    "      distances = list(np.sum(np.subtract(fvec, p)**2) for p in prototypes)\n",
    "      #print(min(distances))\n",
    "      min_dist_index = distances.index(min(distances))\n",
    "\n",
    "      #determine winner prototype\n",
    "      winner =prototypes[min_dist_index]\n",
    "      winner_label=proto_labels[min_dist_index]\n",
    "\n",
    "\n",
    "      #push or repel the prototype based on the label\n",
    "      if winner_label == lbl:\n",
    "        sign = 1\n",
    "      else:\n",
    "        sign = -1\n",
    "\n",
    "      #update winner prototype\n",
    "      prototypes[min_dist_index] = np.add(prototypes[min_dist_index], np.subtract(fvec, winner) * learning_rate * sign)\n",
    "\n",
    "    #use validation set to test the performance\n",
    "    val_err =0\n",
    "    if validation_labels is not None:\n",
    "      for fvec, lbl in zip (validation_data, validation_labels):\n",
    "        distances = list(np.sum(np.subtract(fvec,p)**2) for p in prototypes)\n",
    "        min_dist_index= distances.index(min(distances))\n",
    "\n",
    "        #determine winner prototype label\n",
    "        winner_label = proto_labels[min_dist_index]\n",
    "\n",
    "        #check if labels match\n",
    "        if not winner_label ==lbl:\n",
    "          val_err = val_err +1\n",
    "\n",
    "      val_err = val_err/len(validation_labels)\n",
    "      print(\"Epoch\" + str(epoch) + \". Validation error: \" + str(val_err))\n",
    "    else:\n",
    "      print(\"Epoch\" + str(epoch))\n",
    "\n",
    "  return(prototypes, proto_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 [3.15276596e-01 2.98404255e-01 1.35106383e-01 2.44680851e-02\n",
      " 2.12765957e-02 6.96808511e-02 9.04255319e-02 3.08510638e-02\n",
      " 7.44680851e-02 6.43617021e-02 1.52127660e-01 3.03191489e-02\n",
      " 8.51063830e-03 9.73404255e-02 5.35106383e-01 3.65425532e-01\n",
      " 2.12765957e-03 8.67021277e-02 4.41489362e-02 1.06382979e-01\n",
      " 2.27127660e-01 5.31914894e-04 1.26595745e-01 3.55851064e-01\n",
      " 5.26595745e-02 0.00000000e+00 9.06382979e-01 9.36170213e-02\n",
      " 5.33510638e-01 4.42021277e-01 2.44680851e-02 1.43085106e-01\n",
      " 8.32446809e-01 2.44680851e-02]\n",
      "1 [3.03875757e-01 2.48441247e-01 2.32476876e-01 3.90544707e-02\n",
      " 2.63103803e-02 7.20794793e-02 3.25453923e-02 3.50119904e-02\n",
      " 9.68139774e-02 1.62384378e-02 1.67317575e-01 2.66529633e-02\n",
      " 7.05721137e-03 1.14628297e-01 6.07399794e-01 2.76533059e-01\n",
      " 1.43884892e-03 1.03117506e-01 5.70058239e-02 1.53545735e-01\n",
      " 2.29599178e-01 4.11099692e-04 1.30044536e-01 2.85919836e-01\n",
      " 4.03562864e-02 6.85166153e-05 7.76909901e-01 2.23021583e-01\n",
      " 5.24494690e-01 4.51935594e-01 2.35697157e-02 1.49777321e-01\n",
      " 8.26652963e-01 2.35697157e-02]\n",
      "Epoch0. Validation error: 0.00040464532836968396\n",
      "Epoch1. Validation error: 0.00048557439404362077\n",
      "Epoch2. Validation error: 0.00048557439404362077\n",
      "Epoch3. Validation error: 0.00048557439404362077\n",
      "Epoch4. Validation error: 0.0004451098612066524\n",
      "Epoch5. Validation error: 0.0003641807955327156\n",
      "Epoch6. Validation error: 0.00040464532836968396\n",
      "Epoch7. Validation error: 0.0003641807955327156\n",
      "Epoch8. Validation error: 0.00028325172985877876\n",
      "Epoch9. Validation error: 0.00024278719702181038\n",
      "Epoch10. Validation error: 0.00024278719702181038\n",
      "Epoch11. Validation error: 0.00024278719702181038\n",
      "Epoch12. Validation error: 0.00020232266418484198\n",
      "Epoch13. Validation error: 0.00020232266418484198\n",
      "Epoch14. Validation error: 0.00020232266418484198\n",
      "Epoch15. Validation error: 0.00020232266418484198\n",
      "Epoch16. Validation error: 0.00020232266418484198\n",
      "Epoch17. Validation error: 0.00020232266418484198\n",
      "Epoch18. Validation error: 0.00020232266418484198\n",
      "Epoch19. Validation error: 0.00020232266418484198\n",
      "Epoch20. Validation error: 0.00020232266418484198\n",
      "Epoch21. Validation error: 0.00020232266418484198\n",
      "Epoch22. Validation error: 0.00020232266418484198\n",
      "Epoch23. Validation error: 0.00020232266418484198\n",
      "Epoch24. Validation error: 0.00020232266418484198\n",
      "Epoch25. Validation error: 0.00020232266418484198\n",
      "Epoch26. Validation error: 0.00020232266418484198\n",
      "Epoch27. Validation error: 0.00020232266418484198\n",
      "Epoch28. Validation error: 0.00020232266418484198\n",
      "Epoch29. Validation error: 0.00020232266418484198\n"
     ]
    }
   ],
   "source": [
    "#y_train_num = y_train.replace({'yes': 0, 'no': 1}, inplace=False)\n",
    "#y_test_num = y_test.replace({'yes': 0, 'no': 1}, inplace=False)\n",
    "(a, b) = train_lvq(x_train, y_train, 30, 0.04, x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "opposites=list(map(lambda s: s[0], filter(lambda s: s[1] == 2, zip(x_train.values,y_train_num))))\n",
    "#opposites=map(lambda s: s[0], opposites)\n",
    "mean = np.mean(opposites, axis=1)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1441d2887804a790b4c96588033b1314f9f1095b4a278723188d857f55228eee"
  },
  "kernelspec": {
   "display_name": "Python 3.7.11 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
